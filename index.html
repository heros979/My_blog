<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Peizheng&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Peizheng&#039;s Blog"><meta name="msapplication-TileImage" content="/img/logo.jpg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Peizheng&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Peizheng&#039;s Blog"><meta property="og:url" content="http://oxixo.fun/"><meta property="og:site_name" content="Peizheng&#039;s Blog"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://oxixo.fun/img/og_image.png"><meta property="article:author" content="Wang Peizheng"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://oxixo.fun"},"headline":"Peizheng's Blog","image":["http://oxixo.fun/img/og_image.png"],"author":{"@type":"Person","name":"Wang Peizheng"},"description":""}</script><link rel="alternate" href="/atom.xml" title="Peizheng&#039;s Blog" type="application/atom+xml"><link rel="icon" href="/img/logo.jpg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.3.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.jpg" alt="Peizheng&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item is-active" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/heros979"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-image"><a class="image is-7by3" href="/2020/03/20/deep-learning/"><img class="fill" src="/asset/AI.jpeg" alt="深度学习"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-03-20T02:45:58.000Z" title="2020-03-20T02:45:58.000Z">2020-03-20</time>发表</span><span class="level-item"><time dateTime="2021-02-01T15:09:22.710Z" title="2021-02-01T15:09:22.710Z">2021-02-01</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="level-item">8 分钟读完 (大约1222个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/03/20/deep-learning/">深度学习</a></h1><div class="content"><h2 id="回顾机器学习"><a href="#回顾机器学习" class="headerlink" title="回顾机器学习"></a>回顾机器学习</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>一个计算机程序，针对某个特定任务，从历史数据学习，并且越做越好。<br><img src="/asset/whatisml.png" alt="机器学习过程"></p>
<h3 id="机器学习的核心"><a href="#机器学习的核心" class="headerlink" title="机器学习的核心"></a>机器学习的核心</h3><ul>
<li>数据</li>
<li>模型<h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3></li>
<li>有监督学习<ul>
<li>回归<ul>
<li>线性回归</li>
</ul>
</li>
<li>分类<ul>
<li>SVM<br><img src="/asset/svm.jpg" alt="SVM"></li>
</ul>
</li>
</ul>
</li>
<li>无监督学习<ul>
<li>聚类</li>
<li>主成分分析</li>
</ul>
</li>
<li>半监督学习</li>
<li>增强学习(Reinforcement Learning)<h3 id="学习过程-监督学习"><a href="#学习过程-监督学习" class="headerlink" title="学习过程(监督学习)"></a>学习过程(监督学习)</h3></li>
<li>损失函数(loss function)</li>
<li>优化方法</li>
<li>梯度下降<br><img src="/asset/gradient.jpeg" alt="梯度下降"><h2 id="深度学习是什么"><a href="#深度学习是什么" class="headerlink" title="深度学习是什么"></a>深度学习是什么</h2><blockquote>
<p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">wiki</a>：深度学习（英语：Deep Learning）是机器学习的分支，是一种以人工神经网络为架构，对数据进行表征学习的算法。</p>
</blockquote>
</li>
</ul>
<p><img src="/asset/dltoml.jpg" alt="深度学习与机器学习的关系"><br><strong><center>深度学习是机器学习的子集</center></strong></p>
<h2 id="深度学习和传统机器学习算法的异同"><a href="#深度学习和传统机器学习算法的异同" class="headerlink" title="深度学习和传统机器学习算法的异同"></a>深度学习和传统机器学习算法的异同</h2><h3 id="数据方面"><a href="#数据方面" class="headerlink" title="数据方面"></a>数据方面</h3><blockquote>
<p>Andrew Ng：“与深度学习类似的是，火箭发动机是深度学习模型，燃料是我们可以提供给这些算法的海量数据。</p>
</blockquote>
<p><img src="/asset/dl_data.jpg" alt="深度学习与数据的关系"></p>
<h3 id="计算量方面"><a href="#计算量方面" class="headerlink" title="计算量方面"></a>计算量方面</h3><p>深度学习在更新模型网络权重时涉及大量矩阵运算，在CPU上跑速度会很慢，而传统机器学习算法随便一台电脑就可以跑。因此深度学习最好在GPU上跑。</p>
<p>耗时量级：</p>
<ul>
<li>传统机器学习：秒、分钟、小时</li>
<li>深度学习：小时、天、周</li>
</ul>
<h3 id="输入特征方面"><a href="#输入特征方面" class="headerlink" title="输入特征方面"></a>输入特征方面</h3><p>机器学习依赖于人类精心设计的特征才能取得较好的结果，深度学习主张让算法自己从原始数据中发现特征。不用太过高深的先验知识做支撑，但因此对数据量的需求比较大。</p>
<h2 id="深度学习算法"><a href="#深度学习算法" class="headerlink" title="深度学习算法"></a>深度学习算法</h2><h3 id="人工神经网络-ANN"><a href="#人工神经网络-ANN" class="headerlink" title="人工神经网络(ANN)"></a>人工神经网络(ANN)</h3><p><img src="/asset/deeplearning.jpg" alt="ANN"><br>其中的一个节点：<br><img src="/asset/ANN.jpg" alt="ANN"><br>激活函数一定是一个非线性函数，用来增加网络的复杂性。不然不管网络有多少层，始终是一个线性函数。<br>常用激活函数：</p>
<ul>
<li>relu<ul>
<li>x if x &gt; 0</li>
<li>0 if x &lt;= 0</li>
</ul>
</li>
<li>tanh</li>
</ul>
<h3 id="卷积神经网络-CNN"><a href="#卷积神经网络-CNN" class="headerlink" title="卷积神经网络(CNN)"></a>卷积神经网络(CNN)</h3><h4 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h4><p>在深度学习里的卷积,与数学上的和信号处理上关于卷积的概念有些不同.<br><img src="/asset/juanji.jpg" alt="卷积"></p>
<h4 id="CNN结构"><a href="#CNN结构" class="headerlink" title="CNN结构"></a>CNN结构</h4><p>两条基本假设：</p>
<ul>
<li>最底层特征都是局部性的，也就是说，我们用10x10这样大小的过滤器就能表示边缘等底层特征</li>
<li>图像上不同位置处特征是类似的，也就是说，我们能用同样的一组分类器来描述不同位置的图像——<strong>平移不变性</strong></li>
</ul>
<p><img src="/asset/CNN.jpg" alt="CNN"><br>关键：<strong>局部连接，权值共享，池化</strong></p>
<p>CNN在处理图像数据时与ANN相比有着巨大的优势，通过局部连接、权值共享和池化大大减少了参数的数量，从而大大减少计算量、减少过拟合并大大提高模型的表现。</p>
<h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><p><a target="_blank" rel="noopener" href="http://peizhengyijiaqin.me/2019/12/14/ml-start/#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0">模型训练</a>的过程可以认为是使损失函数最小化的过程<br><img src="/asset/learn.gif" alt="学习过程"></p>
<h3 id="模型泛化与过拟合、欠拟合问题"><a href="#模型泛化与过拟合、欠拟合问题" class="headerlink" title="模型泛化与过拟合、欠拟合问题"></a>模型泛化与过拟合、欠拟合问题</h3><p>因为深度学习的表达能力很强，当你的模型的表现很好时，你需要警惕，是模型学到了规律还是说模型记住了数据。检测方法也很简单，前者在一个陌生的数据集上表现依然很好，而后者反之。因此，在设计模型的时候也要考虑使用一些方式来尽可能的避免过拟合，从而得到较好的泛化能力。</p>
<p><img src="/asset/fit.jpg" alt="fit"></p>
<h3 id="书籍推荐"><a href="#书籍推荐" class="headerlink" title="书籍推荐"></a>书籍推荐</h3><p>入门书籍：<br>该书简单易懂，为keras之父写的书。好上手，学了就能用，里面有很多demo可以跑。<br><img src="/asset/keras_book.jpg" alt="keras"></p>
<p>进阶书籍：<br>该书讲了很多数学、线代、概率论还有优化的东西，被奉为深度学习圣经，俗称“花书”，适合作为工具书，在手边随时查阅，入门较吃力。<br><img src="/asset/book.jpg" alt="花书"></p>
<h3 id="主流深度学习框架"><a href="#主流深度学习框架" class="headerlink" title="主流深度学习框架"></a>主流深度学习框架</h3><ul>
<li>Tensorflow</li>
<li>Pytorch</li>
<li>Keras</li>
<li>Paddlepaddle</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li>人工智能&gt;机器学习&gt;深度学习</li>
<li>需要更多的数据量和算力</li>
<li>ANN<ul>
<li>输出是输入的复杂非线性函数</li>
</ul>
</li>
<li>CNN<ul>
<li>局部连接</li>
<li>权值共享</li>
<li>池化</li>
</ul>
</li>
<li>模型训练<ul>
<li>损失函数</li>
<li>梯度下降</li>
</ul>
</li>
<li>注意过拟合与欠拟合</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-01-15T23:50:02.000Z" title="2020-01-15T23:50:02.000Z">2020-01-16</time>发表</span><span class="level-item"><time dateTime="2021-02-01T15:10:31.506Z" title="2021-02-01T15:10:31.506Z">2021-02-01</time>更新</span><span class="level-item"> 钟昊均 </span><span class="level-item"><a class="link-muted" href="/categories/%E7%89%A9%E7%90%86/">物理</a></span><span class="level-item">12 分钟读完 (大约1824个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/01/16/zhj-2/">果壳中的经典统计</a></h1><div class="content"><h1 id="果壳中的经典统计"><a href="#果壳中的经典统计" class="headerlink" title="果壳中的经典统计"></a><center>果壳中的经典统计</center></h1><center>钟昊均</center>

<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><center>摘要</center></h2><p>&emsp;&emsp;一直想写一个有关经典统计的note，结合凝聚态场论学习中的一些经验，趁此机会写点我自己对经典统计的理解。</p>
<h2 id="统计方法的引入"><a href="#统计方法的引入" class="headerlink" title="统计方法的引入"></a>统计方法的引入</h2><p>&emsp;&emsp;在经典力学的框架下，我们可以通过构造系统的拉格朗日量或哈密顿量来求出描述系统演化的拉格朗日方程或者正则方程，进而求解系统的各项性质。这种从最多的自由度出发精确求解系统相轨道的方法在数学上是困难的，从微分方程理论的角度来说，系统自由度的增加会极大地增加求解方程的困难，对于某些相互作用还会导致系统不可积，而且一旦方程是非线性的，这个系统就很有可能是极端初值依赖的，这使得对系统进行长时间的预测变为不可能，这些性质决定了运动方程在刻画多体系统上的不完备性。</p>
<p>&emsp;&emsp;但是，对于多体系统，我们真的有必要精确求解这个系统吗？统计方法告诉我们，如果我们将尺度放到整个多体系统或者某个整体的多体子系统的层次并且给定一个简单的假设，我们就能从巨大的自由度中得到很多非平凡的结论，这就是经典统计方法带来的优势。微正则系综处理的是不满足KAM定理的保守不可积系统，对于不可积系统是不存在力学解析解的，而不满足KAM定理的要求会带来相轨道的遍历性（满足KAM定理的系统即使存在微扰也会保KAM环面的拓扑，哈密顿相流是必然不遍历的，因此从力学出发是不可能导出统计方法的），对于能量约束下形成的相空间上的球面来说，哈密顿相流的遍历性启发我们用系综平均来取代瞬时的体系参量以描述统计系统，同时如果给定一个更强的等概率原理（其实可以理解成相空间中态上的随机行走，这一点是比遍历性要求更高的），我们就能够给出微正则系综的数学描述，但是接下来就牵涉到系综平均和时间平均是否等价的问题。</p>
<p>&emsp;&emsp;KAM定理的要求是在哈密顿量的可积部分上加上一项微扰项，微扰失效的情况下才会给系统引入遍历性，因此遍历性是统计方法的基本假设，在遍历性假设下时间平均才等于系综平均（哈密顿相流在能量球面上的随机行走轨迹能完全填充球面），但是实际上我们处理的很多系统的相互作用能不能打破KAM环面的拓扑是存疑的，在很多非线性系统中存在的吸引子也能够引发遍历性破缺。在我们的统计物理中，环境的噪声就被当成遍历性假设成立的解释之一，毕竟对于初值敏感的系统，噪声带来的微扰是影响巨大的。当然对于经典系统，能量很自然地假设是连续变化的，这个也是经典统计的一大基本假设。</p>
<h2 id="经典统计的局限性"><a href="#经典统计的局限性" class="headerlink" title="经典统计的局限性"></a>经典统计的局限性</h2><p>&emsp;&emsp;经典统计的局限性在很多微观体系中其实已经浮现，比如在固体比热和多原子分子气体乃至黑体辐射的分析中就已经一窥踪影。其原因无外乎三点：1、能级的不连续性被极小的宏观平均能级差隐藏；2、自旋乃至更高的自由度没有被考虑；3、能量表象下简并度被忽略。</p>
<p>&emsp;&emsp;在我看来，第三点是经典统计最容易引入的修正，因为这个简并度在从微正则系综到正则系综的映射中就已经隐含了。微正则系综作为孤立系，在相空间中的自由度是最大的，需要考虑孤立系中全部子系统的轨迹，但是一旦我们考虑一个温度恒定的热源，通过积分积去环境带来的自由度，这样就完成了从微正则系综到正则系综的跃变。在这个过程中，很明显，被隐藏的自由度会带来更高的对称性，以至于在任意表象下都会引入非平庸的分布函数，但是目前我们刻意地只保留了指数的部分而忽略了具体表象下存在的其余对称性，比如k空间中谐振子波模就是存在简并度的，这一点在黑体辐射的经典分析中已经得到体现。</p>
<p>&emsp;&emsp;对于凝聚态体系，自旋都是极其重要的，自旋自由度就是磁性系统的基础，但是对于自旋，我们也可以在完全应用量子场论之前做一点经典的统计，比如著名的伊辛模型，这个经典的自旋体系（区别于海森堡模型的自旋）可以做平均场，当然对于一维的伊辛模型的平均场得出的有限温相变点是很离谱的错误，但这不妨碍做高维的伊辛模型平均场（精确很多），这个模型往里挖还能引入很多新的思想，比如重整化，这里就不继续讨论了。</p>
<p>&emsp;&emsp;能级不连续作为两朵大乌云中的一朵，在黑体辐射的研究被揭露了出来，无相互作用玻色子系统的能隙是产生玻色-爱因斯坦凝聚的关键，实验上在多原子分子的平均能量中我们也能看到阶梯状的随温度变化的情形，经典统计是得不出这样奇妙的结果的，毕竟经典系统是无能隙的。</p>
<h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>&emsp;&emsp;经典统计是研究多体系统的重要工具，也是进入量子统计的基础，在经典统计中很多方法在量子统计中依然有用武之地，比如平均场和团簇展开都是非常常见的技术，其思想更是在物理学中占有极重的地位，因此经典统计对于我们的同学实属应该学好、必须学好的一种理论，这对今后的学习与研究都是有大益处的。</p>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2020/01/16/zhj-1/"><img class="fill" src="/asset/ldlx.jpg" alt="读朗道力学有感——以最小作用量原理为第一性原理的经典演绎"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-01-15T23:49:54.000Z" title="2020-01-15T23:49:54.000Z">2020-01-16</time>发表</span><span class="level-item"><time dateTime="2021-02-01T15:10:26.576Z" title="2021-02-01T15:10:26.576Z">2021-02-01</time>更新</span><span class="level-item"> 钟昊均 </span><span class="level-item"><a class="link-muted" href="/categories/%E7%89%A9%E7%90%86/">物理</a></span><span class="level-item">9 分钟读完 (大约1413个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/01/16/zhj-1/">读朗道力学有感——以最小作用量原理为第一性原理的经典演绎</a></h1><div class="content"><h1 id="读朗道力学有感——以最小作用量原理为第一性原理的经典演绎"><a href="#读朗道力学有感——以最小作用量原理为第一性原理的经典演绎" class="headerlink" title="读朗道力学有感——以最小作用量原理为第一性原理的经典演绎"></a>读朗道力学有感——以最小作用量原理为第一性原理的经典演绎</h1><center>钟昊均</center>

<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><center>摘要</center></h2><p>&emsp;&emsp;朗道力学行文之简洁有力的基础，我认为是抓住了经典力学的本质——最小作用量原理，并以其为第一性原理，通过变分法的数学演绎来建立整个经典力学体系。</p>
<h2 id="拉格朗日分析"><a href="#拉格朗日分析" class="headerlink" title="拉格朗日分析"></a>拉格朗日分析</h2><p>&emsp;&emsp;很多人认为朗道的书很难，但我认为难的其实并不是朗道书里面花哨的积分或者各种推导技巧，难的是朗道在书中体现的对理论体系的物理本质的思考。比如在拉格朗日函数等于T-V的推导时，其实是合理地从积分泛函的物理本质结合数学结构的基础上合理猜出了动能在笛卡尔坐标中的一般形式，顺便还得出了笛卡尔系下质量的定义——拉格朗日函数对伽利略变换时全导数项的乘数因子。在建立三大守恒律与三大对称性的桥梁时更是体现了朗道对对称性的深刻理解，通过不变量的构造展现了诺特定理的内涵，不过没有在书中完整地展现和演绎诺特定理是有点遗憾的。</p>
<p>&emsp;&emsp;这样的演绎方法最大的好处就是理论的结构和体系非常完整和优美，在具体力学过程的演绎上也是从拉格朗日函数上出发利用拉氏方程来解决具体问题。我以为正是广义坐标的引入体现了力学体系的一般性，这使得拉格朗日力学具有普适性，通过在逻辑上先不考虑约束的存在，而后再通过约束减少方程个数，这也使得拉格朗日力学相比利用几何约束来构造牛顿方程的牛顿力学更加自然，这些共同形成了拉格朗日力学对牛顿力学的先进性——本质上完成了力学空间从欧氏空间到位形空间的拓展。</p>
<h2 id="哈密顿分析"><a href="#哈密顿分析" class="headerlink" title="哈密顿分析"></a>哈密顿分析</h2><p>&emsp;&emsp;但是这对于经典力学的研究并没有画上一个句号——力学的几何特征并没有在拉格朗日力学中得到最大的显现。对于定义在位形空间的拉氏力学而言，一个可积系统在宏观上很有可能是杂乱无章的，比如对于统计物理中的各种模型，使用拉氏量来描述体系是不够能体现体系的某些共同特征的；同时在处理坐标和速度的地位上也是有一点缺憾的——位置和速度可以分别同时给定，这就隐含了位置与速度在描述运动的地位上是不是可以相等的问题。这时，利用勒让德变换就能够将拉格朗日力学过渡到更加先进的哈密顿力学上来。</p>
<p>&emsp;&emsp;勒让德变换在变换拉格朗日函数的时候很像分部积分，通过对微分拉氏量的数学变换，可以构造出一个以广义动量和广义坐标为变量的描述力学的量——哈密顿量。哈密顿力学的威力就在于更高的对称性，通过参数空间的拓展，由哈密顿量导出的正则方程拥有了拉氏方程不具有的高对称性，同时方程阶数由二阶降到一阶、方程个数则翻了倍，我们由此可以从正则方程中得到更多对系统的描述，在数值计算时甚至可以提高效率和可靠性。这种对称性使得定义在“相空间”的哈密顿力学有能力开始展现更多的力学系统的几何特征，力学系统在相空间中可以自然形成流形，同时刘维尔定理告诉我们相空间体积元对正则变换不变，这给了我们研究力学系统在相空间中流形上的性质时最好的工具，正如朗道在“正则变换”一节中说的那样：“对这种可能变换类型的扩大是力学的哈密顿方法的重要优点之一”。</p>
<p>&emsp;&emsp;当然，哈密顿力学中的重要概念——泊松括号，这种算符的存在使得运动积分的构造变得程序化，毕竟两个运动积分的泊松括号也是运动积分，这对于力学的不变量理论是极其重要的。但是泊松括号的意义不仅仅在于此，其在量子力学中的映射——对易子算符对量子力学具有重要意义。</p>
<h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>&emsp;&emsp;从朗道力学的目录来看，全书非常精炼，为了完成力学体系的构造，没有一节是冗余的，信息量非常大，在研读哈密顿力学之时有很多推导的细节都非常强调亲手推导，这种高屋建瓴的视角正是理论工作者所需要的。</p>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2019/12/17/poem3/"><img class="fill" src="/asset/hiding.jpg" alt="Third Poem"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-12-17T14:16:00.000Z" title="2019-12-17T14:16:00.000Z">2019-12-17</time>发表</span><span class="level-item"><time dateTime="2020-01-11T14:33:00.878Z" title="2020-01-11T14:33:00.878Z">2020-01-11</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%AF%97%E9%9B%86/">诗集</a></span><span class="level-item">几秒读完 (大约98个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/12/17/poem3/">Third Poem</a></h1><div class="content"><p><font face="Times New Roman" size=6>HIDING</font><br><br><br><font face="Monotype Corsiva" size=6>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;—-Evie</font><br><br></p>
<font face="Ink Free" size=5>
Booming, booming bus.<br>
Rains dropped on the windows.<br>
Outside is the dusky sky<br>
With dark clouds hiding somewhere.<br>
Inside is a complacent heart<br>
Without being complimenting.<br>
<br>
Hiding the disappointment <br>
From a beautiful fragile mind,<br>
Where intellect should always stand.<br>
I show my courage<br>
to my cold little heart,<br>
which might suffer <br>
from wild heat of tricking,<br>
but would not go into hiding<br>
Any more.<br>
<br>

</font> 
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2019/12/14/ml-start/"><img class="fill" src="/asset/AI.jpeg" alt="机器学习概览"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-12-14T04:07:39.000Z" title="2019-12-14T04:07:39.000Z">2019-12-14</time>发表</span><span class="level-item"><time dateTime="2021-02-01T15:09:35.734Z" title="2021-02-01T15:09:35.734Z">2021-02-01</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="level-item">14 分钟读完 (大约2165个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/12/14/ml-start/">机器学习概览</a></h1><div class="content"><h2 id="机器学习是什么"><a href="#机器学习是什么" class="headerlink" title="机器学习是什么"></a>机器学习是什么</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">wiki</a>：机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。</p>
</blockquote>
<blockquote>
<p>Arthur samuel：机器学习是在不直接针对问题进行编程的情况下，赋予计算机学习能力的一个研究领域。</p>
</blockquote>
<p>一个计算机程序，针对某个特定任务，从历史数据学习，并且越做越好。</p>
<p>让我<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/25ef14c072ad">引用</a>一张图片来说明：<br><img src="/asset/whatisml.png" alt="机器学习过程"><br>注意：这里是用有监督模型举例(后面会对这个名词进一步解释)</p>
<h3 id="针对机器学习最重要的内容"><a href="#针对机器学习最重要的内容" class="headerlink" title="针对机器学习最重要的内容"></a>针对机器学习最重要的内容</h3><ul>
<li>数据：经验只有转化为了计算机能够理解的数据，才能让计算机从中学习。谁的数据量大、质量高，谁就占据了机器学习和人工只能领域最有利的资本。</li>
<li>模型：即算法，有了数据之后，可以设计模型，通过数据来训练这个模型。这个模型就是机器学习的核心，作为用来产生决策的中枢。</li>
</ul>
<h3 id="数据的分类"><a href="#数据的分类" class="headerlink" title="数据的分类"></a>数据的分类</h3><ul>
<li>结构化数据———储存在数据库中的数据</li>
<li>非结构化数据——-语音信号、图像图形、自然语言</li>
</ul>
<h2 id="机器学习能干什么"><a href="#机器学习能干什么" class="headerlink" title="机器学习能干什么"></a>机器学习能干什么</h2><ul>
<li>语音识别、机器翻译(微软Cortana、苹果Siri、科大讯飞、谷歌翻译)</li>
<li>人脸识别(微信、支付宝、宿舍门禁)</li>
<li>量化交易(预测股市)</li>
<li>房价预测</li>
<li>推荐系统(淘宝、京东、抖音)</li>
<li>医生/老中医</li>
<li>解微分方程、不定积分(见：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/98174049?utm_source=zhihu&utm_medium=social&utm_oi=667848254054731776">AI拿下高数一血，求解微分方程、不定积分只需1秒，成绩远超Matlab</a>)</li>
<li>寻找淹没在背景噪声中的小信号(<a target="_blank" rel="noopener" href="https://www.kaggle.com/c/higgs-boson">Higgs Boson Machine Learning Challenge</a>、引力波信号、引力透镜参数预测)</li>
</ul>
<h2 id="好用的机器学习库以及书籍推荐"><a href="#好用的机器学习库以及书籍推荐" class="headerlink" title="好用的机器学习库以及书籍推荐"></a>好用的机器学习库以及书籍推荐</h2><p>scikit-learn：最有名且易用好上手，广泛作为机器学习的入门库(Python)<br>书籍：<img src="/asset/scikit.png" alt="scikit-learn机器学习"></p>
<h2 id="机器学习的分类"><a href="#机器学习的分类" class="headerlink" title="机器学习的分类"></a>机器学习的分类</h2><p>按照模型的学习方式，我们可以分为如下几类：</p>
<h3 id="有监督学习"><a href="#有监督学习" class="headerlink" title="有监督学习"></a>有监督学习</h3><p>对于数据集中的每一条数据，我们在把它交给算法前就有了相应的“正确答案”，我们的算法就是在基于这些我们人为给定的“正确答案”在做预测。</p>
<p>有监督学习的任务一般是回归或者分类问题：</p>
<ul>
<li>回归：线性回归<br>比如通过商品房的地段、高度、外形、面积、采光面积等参数来预测商品房价格。预测结果是一个连续的值。</li>
<li>分类：支持向量机(SVM)、决策树、逻辑回归、朴素贝叶斯、KNN<br>比如通过西瓜的颜色、大小、重量、花纹等等预测西瓜甜不甜。<br>请注意，这里我们预测的输出只包括甜和不甜，是一个离散值，这是一个二分类的问题。<br>反之，若是我们输出的是西瓜介于0到1之间的的甜度(0是一点都不甜，1是超级甜)，那这个分类问题就转化为了回归问题。</li>
</ul>
<h3 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h3><p>对于数据集中的所有数据，他们没有一个相应的“正确答案”。算法要做的是利用算法自动的将数据归类，也叫做<strong>聚类</strong>。</p>
<ul>
<li>KMEAN</li>
</ul>
<h3 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h3><p>介于监督学习和无监督学习之间的一种方式。即一部分数据有标记，一部分数据没有标记。</p>
<h3 id="增强学习"><a href="#增强学习" class="headerlink" title="增强学习"></a>增强学习</h3><p>增强学习是一种有反馈的学习方式。</p>
<p>例子：贪吃蛇问题<br>一个N×N的格子里，定义贪吃蛇每一步上下左右随机行走，碰到墙或者自身则得到负反馈，吃到果子得到正反馈，在训练很多轮以后，贪吃蛇就学会了如何躲避墙和自身去吃果子。</p>
<h2 id="机器学习的一般步骤"><a href="#机器学习的一般步骤" class="headerlink" title="机器学习的一般步骤"></a>机器学习的一般步骤</h2><h3 id="数据采集和标记"><a href="#数据采集和标记" class="headerlink" title="数据采集和标记"></a>数据采集和标记</h3><ul>
<li>构建数据集：收集尽可能的多的特征，给出数据标记（人工或自动）</li>
</ul>
<p>预测房价：面积大小、房间数、地段、楼龄等；<br>芝麻信用：海量的用户交易数据；</p>
<h3 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h3><ul>
<li>对数据中的单位进行统一</li>
<li>去掉重复数据、噪声和数据缺失</li>
</ul>
<h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><ul>
<li>从哪些特征对进行机器学习是有用的；人工设计或自动选择</li>
</ul>
<h3 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h3><ul>
<li>根据问题选择模型，聚类还是分类，回归还是分类</li>
</ul>
<h3 id="模型训练和测试"><a href="#模型训练和测试" class="headerlink" title="模型训练和测试"></a>模型训练和测试</h3><ul>
<li>把数据集合分为训练集和测试集，用训练集训练模型，训练完成后用测试集测试模型的精度。(测试集必须是模型没有见过的数据)</li>
</ul>
<h3 id="模型性能评估与优化"><a href="#模型性能评估与优化" class="headerlink" title="模型性能评估与优化"></a>模型性能评估与优化</h3><ul>
<li>训练时长，训练数据是否足够，是否能满足需要</li>
</ul>
<h3 id="模型使用"><a href="#模型使用" class="headerlink" title="模型使用"></a>模型使用</h3><ul>
<li>训练好的模型进行存储，以备下次使用</li>
</ul>
<h2 id="机器如何学习"><a href="#机器如何学习" class="headerlink" title="机器如何学习"></a>机器如何学习</h2><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>例如：<br>用一维线性回归举例:</p>
<p> $$ y = kx+b $$</p>
<p>x就是我们的input，y就是我们的label，我们首先给算法一定的(x,y)数据，算法拟合出来一条直线方程，当我们再输入x数据时，模型能够预测出相应的y。这就是一个简单的有监督机器学习例子。但是，机器怎么知道哪个k和b是最好的呢？</p>
<p>也就是说，我们需要用一个指标来衡量模型和数据的拟合程度，而模型的预测值和真实值的差，我们叫做<strong>损失函数</strong>。在这里，我们训练的一个线性回归模型，可以是让MSE(均方误差)最小，MSE在这里被称为这个回归模型的<strong>损失函数</strong>，它代表了预测值与真实值的偏离程度。而我们机器学习的过程就是通过改变k和b使得<strong>损失函数</strong>取得<strong>最小值</strong>。<br>$$<br>L_{MSE}(\hat{y}, y)=\frac{1}{m} \sum_{i=1}^{m}\left(y_{i}-\hat{y}_{i}\right)^{2}<br>$$<br>这里的m表示数据个数。</p>
<p>除此之外，对于<strong>二分类</strong>问题来说，常用的损失函数是二元交叉熵损失(Logistic损失):</p>
<p>$$<br>L_{\text {logistic }}(\hat{y}, y)=\frac{1}{m} \sum_{i=1}^{m}[-y_{i} \log \hat{y}<em>{i}-\left(1-y</em>{i}\right) \log \left(1-\hat{y}_{i}\right)]<br>$$</p>
<p>这里的 $\hat{y}$ 代表预测y=1的概率。</p>
<h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h3><p>我们知道了我们的目标是让k和b最小，那我们怎么实现呢？接下来我们来看一下它的解决方案——使用<strong>梯度下降</strong>算法来更新参数。</p>
<p><img src="/asset/gradient.jpeg" alt="梯度下降"></p>
<p>这里 $\theta_0$ 和 $\theta_1$ 分别代表k和b。</p>
<p>我们从一个随机的k和b出发，沿着向下最快的路径行走，直到达到最低点，即此时k和b收敛于一个定值，这个定值就是我们想要得到的使得损失函数最小的值。</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>本文使用scikit-learn实现一个线性回归模型举例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression <span class="comment">#从sklearn引入线性回归模型</span></span><br><span class="line">model=LinearRegression()                          <span class="comment">#声明线性回归模型</span></span><br><span class="line">model.fit(X_train,Y_train)                        <span class="comment">#用训练数据训练模型</span></span><br><span class="line">Y_pred=model.predict(X_test)                      <span class="comment">#用模型对测试数据做预测</span></span><br><span class="line">print(Y_pred)                                     <span class="comment">#输出预测结果</span></span><br></pre></td></tr></table></figure>
<p>常用的API有：</p>
<table>
  <tr>
    <th>API</th>
    <th>解释</th>
  </tr>
  <tr>
    <td>fit(X_train,Y_train)</td>
    <td>训练模型</td>
  </tr>
    <tr>
    <td>predict(X_test)</td>
    <td>预测测试数据的结果</td>
  </tr>
    <tr>
    <td>score(X_test,Y_test)</td>
    <td>测试预测数据的score(例如正确率)</td>
  </tr>
</table>

<p>这里只是展示了很少很少的API，还有很多非常非常实用的API及教程参见<a target="_blank" rel="noopener" href="https://sklearn.apachecn.org/">官方文档</a></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>1.获取数据</li>
<li>2.处理数据(80%的时间)</li>
<li>3.训练模型(20%的时间)</li>
<li>4.进行预测</li>
<li>5.观察结果，不满意则重复2.3.4.步，满意则保存模型</li>
</ul>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2019/12/14/poem2/"><img class="fill" src="/asset/pounding.jpg" alt="Second Poem"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-12-13T19:58:00.000Z" title="2019-12-13T19:58:00.000Z">2019-12-14</time>发表</span><span class="level-item"><time dateTime="2020-01-11T14:32:56.430Z" title="2020-01-11T14:32:56.430Z">2020-01-11</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%AF%97%E9%9B%86/">诗集</a></span><span class="level-item">几秒读完 (大约74个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/12/14/poem2/">Second Poem</a></h1><div class="content"><p><font face="Times New Roman" size=6>POUNDING</font><br><br><br><font face="Monotype Corsiva" size=6>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;—-Evie</font><br><br></p>
<font face="Ink Free" size=5>
Pounding, pounding heart,<br>
Why you pump so hard?<br>
Feeling a bunch of vessels<br>
Extending to my roots,<br>
Where blood poured<br>
After running across<br>
Wvery finger of my nerves.<br>
<br>
Who am I<br>
Besides a cluster of cells,<br>
Tramping in the sounds...<br>
<br>

</font> 
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2019/12/12/poem1/"><img class="fill" src="/asset/lost1.jpg" alt="First Poem"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-12-11T16:45:00.000Z" title="2019-12-11T16:45:00.000Z">2019-12-12</time>发表</span><span class="level-item"><time dateTime="2020-01-11T14:32:08.193Z" title="2020-01-11T14:32:08.193Z">2020-01-11</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%AF%97%E9%9B%86/">诗集</a></span><span class="level-item">1 分钟读完 (大约173个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/12/12/poem1/">First Poem</a></h1><div class="content"><p><font face="Times New Roman" size=6>LOST</font><br><br><br><font face="Monotype Corsiva" size=6>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;—-Evie</font><br><br></p>
<font face="Ink Free" size=5>
Chilled night, chilly light, <br>
Wind rolling sky, <br>
Cloud over head. <br>
Ashes tangled my hair, <br>
Mind lost from ear. <br>
<br>
Running from sunlight, <br>
The music ignite a fire, <br>
Lit a face in the dusky theater air; <br>
The dance stepped the melody <br>
Into my eyes gently. <br>
Tears shining <br> 
In the reflected screen light, <br>
Heart flipping <br> 
Over the woebegone rejoicing <br>
With the beauty of art. <br>
<br>
I've lost my blue <br>
From their bloody mouth. <br>
Taping up and down, <br>
Their tip of tongue fan a fame. <br>
When there is no longer a pure face <br>
But tech race on the screen, <br>
They stop looking into themselves. <br>
<br>
I've shut my soul from heat of lies, <br>
But lost in my chilling heart. <br>
Looking outside <br> 
From the window of fear, <br>
Everyone seems to be tired. <br>
Walking over again <br>
Like nothing changed there, <br>
I want my feeling back. <br>

</font> 
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2019/12/11/writing/"><img class="fill" src="/asset/write.jpeg" alt="Hexo+markdown开始博客写作"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-12-11T14:17:30.000Z" title="2019-12-11T14:17:30.000Z">2019-12-11</time>发表</span><span class="level-item"><time dateTime="2021-02-01T15:09:50.448Z" title="2021-02-01T15:09:50.448Z">2021-02-01</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E5%8D%9A%E5%AE%A2/">博客</a></span><span class="level-item">9 分钟读完 (大约1412个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/12/11/writing/">Hexo+markdown开始博客写作</a></h1><div class="content"><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul>
<li>Hexo安装</li>
<li>Hexo使用</li>
<li>Markdown写作</div><a class="article-more button is-small is-size-7" href="/2019/12/11/writing/#more">阅读更多</a></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2019/12/10/blog-init/"><img class="fill" src="/asset/create.jpg" alt="DigitalOcean+Hexo+Nginx+Namecheap搭建个人博客"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-12-10T15:57:14.000Z" title="2019-12-10T15:57:14.000Z">2019-12-10</time>发表</span><span class="level-item"><time dateTime="2021-02-01T14:41:08.984Z" title="2021-02-01T14:41:08.984Z">2021-02-01</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E5%8D%9A%E5%AE%A2/">博客</a></span><span class="level-item">6 分钟读完 (大约906个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/12/10/blog-init/">DigitalOcean+Hexo+Nginx+Namecheap搭建个人博客</a></h1><div class="content"><p>强烈推荐<a target="_blank" rel="noopener" href="https://education.github.com/pack">Github学生包</a>，内含大量对学生的免费福利，包括不限于Jetbrain全家桶，AWS，Azure，DigitalOcean，Namecheap，name等。本文基于Github学生包里的DigitalOcean $50和Namecheap一年个人域名搭建个人博客。</p>
<h2 id="技术架构"><a href="#技术架构" class="headerlink" title="技术架构"></a>技术架构</h2><ul>
<li><p>VPS：<a target="_blank" rel="noopener" href="https://cloud.digitalocean.com/">DigitalOcean</a></p>
</li>
<li><p>域名注册：<a target="_blank" rel="noopener" href="https://www.namecheap.com/">NameCheap</a></p>
</li>
<li><p>博客框架：<a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/">Hexo</a></p>
</li>
<li><p>自动部署：<a target="_blank" rel="noopener" href="https://git-scm.com/">githook</a></p></div><a class="article-more button is-small is-size-7" href="/2019/12/10/blog-init/#more">阅读更多</a></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2019/12/09/summury-of-big-data-competition/"><img class="fill" src="/asset/Big-Data.jpg" alt="2019大数据算法赛总结"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-12-09T02:32:45.000Z" title="2019-12-09T02:32:45.000Z">2019-12-09</time>发表</span><span class="level-item"><time dateTime="2021-02-01T15:09:47.061Z" title="2021-02-01T15:09:47.061Z">2021-02-01</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="level-item">9 分钟读完 (大约1398个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/12/09/summury-of-big-data-competition/">2019大数据算法赛总结</a></h1><div class="content"><p>之前一直对机器学习比较感兴趣，大三开学开始学习深度学习，正巧赶上全国高校计算机挑战赛开赛，就报名了我参加的第一个大数据方向的竞赛。这个比赛入门门槛很低，随便找个模型调用一下sklearn库就能跑出结果，但想争夺一个好的名次还是不太容易。</p>
<h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p>报名费用：¥150（每队）</p>
<p>参加人数： 290队</p>
<p>最终排名： 62</p>
<p>最终得分（AUC）：0.733</p>
<p>使用模型：XGBOOST</p></div><a class="article-more button is-small is-size-7" href="/2019/12/09/summury-of-big-data-competition/#more">阅读更多</a></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/favicon.jpg" alt="Peizheng Wang"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Peizheng Wang</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Chongqing</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">10</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">11</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/heros979" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/heros979"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/%E5%8D%9A%E5%AE%A2/"><span class="level-start"><span class="level-item">博客</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">机器学习</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%89%A9%E7%90%86/"><span class="level-start"><span class="level-item">物理</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%97%E9%9B%86/"><span class="level-start"><span class="level-item">诗集</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div><!--!--><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-03-20T02:45:58.000Z">2020-03-20</time></p><p class="title"><a href="/2020/03/20/deep-learning/">深度学习</a></p><p class="categories"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-01-15T23:50:02.000Z">2020-01-16</time></p><p class="title"><a href="/2020/01/16/zhj-2/">果壳中的经典统计</a></p><p class="categories"><a href="/categories/%E7%89%A9%E7%90%86/">物理</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-01-15T23:49:54.000Z">2020-01-16</time></p><p class="title"><a href="/2020/01/16/zhj-1/">读朗道力学有感——以最小作用量原理为第一性原理的经典演绎</a></p><p class="categories"><a href="/categories/%E7%89%A9%E7%90%86/">物理</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2019-12-17T14:16:00.000Z">2019-12-17</time></p><p class="title"><a href="/2019/12/17/poem3/">Third Poem</a></p><p class="categories"><a href="/categories/%E8%AF%97%E9%9B%86/">诗集</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2019-12-14T04:07:39.000Z">2019-12-14</time></p><p class="title"><a href="/2019/12/14/ml-start/">机器学习概览</a></p><p class="categories"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2020/03/"><span class="level-start"><span class="level-item">三月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/01/"><span class="level-start"><span class="level-item">一月 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/12/"><span class="level-start"><span class="level-item">十二月 2019</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/VPS/"><span class="tag">VPS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/bigdata/"><span class="tag">bigdata</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hexo/"><span class="tag">hexo</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hginx/"><span class="tag">hginx</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/markdown/"><span class="tag">markdown</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/poem/"><span class="tag">poem</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%86%99%E4%BD%9C/"><span class="tag">写作</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%80%BB%E7%BB%93/"><span class="tag">总结</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="tag">机器学习</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BD%91%E7%AB%99/"><span class="tag">网站</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AF%BB%E5%90%8E%E6%84%9F/"><span class="tag">读后感</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.jpg" alt="Peizheng&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2021 Wang Peizheng</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" async></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>